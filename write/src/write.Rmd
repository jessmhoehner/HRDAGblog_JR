---
title: 'From Scripts to Projects: Using a Modular, Auditable, and Reproducible Workflow to Investigate a Potential Epidemic'
author: "Jessica Randall"
date: "12/29/2019"
output:
  bookdown::pdf_document2:
    latex_engine: xelatex
    toc: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction {-}

Having been a big fan of HRDAG's work and fellow alumna of Emory's Rollin's School of Public Health, I have been delighted to have had opportunities to chat with both Megan and Patrick over the last year. I was equally thrilled when Patrick asked if I might want to work on an epidemiological problem the team had been presented with. While I had read about the organization's modular workflow (link) and watched Patrick's talk on how to do principled data processing (link), a lot of it was initially beyond my scope as someone who had only formally learned SAS and dabbled in self-taught Python and R. I fully admit to my R code looking suspiciously similar to all of the examples of amateur coding that Tarak uses in his post on why .Rproj is harmful to reproducible and auditable data science (link). 

Excited to help out where I could and learn from a master, I was undettered by the prospect of a crash course in the HRDAG process necessitated by the inherent immediacy of the need for an answer; were the data suggestive of an epidemic or not? To that end and with a great deal of Patrick's guidance I began to shift towards working mainly in the command line as opposed to R Studio and to start thinking of scripts in terms of a larger project architecture as opposed to one-off bits of code that I'd write per project. 

As I worked, Patrick also encouraged me to keep notes on what I liked and disliked about the process, where I felt it made things easier and where I noticed friction. The following post summarizes those notes and the work that went into determining the answers to the client's question.

## Setup {-}

To begin the project, we start with a task. Each task is a microchasm of the entire project and at HGRAG, not only does this serve to facilitate the team's collaboration across time zones and programming languages. This results in projects which are auditable and have reproducible results; anyone looking at the code can determine exactly how any output from it was produced and anyone working on the task at anytime can pick it up and recreate the same output you wrote. As a scientist, this need for reproducibility resonated with me and even if you are a team of one in your workplace (as many statisticians reading this might be) your closest collaborator is you six months from now. Break up your project into discrete tasks and thank yourself later. I plan to implement this style of project organization even at my work outside of HRDAG.

To make the goals of each task even clearer, each task has a Makefile. The Makefile serves as an outline of each task not only for our benefit, but mainly for the computer to read it. Imagine being able to work on a group project with team members around the world, and still have an auditable trail of each person's work. The Makefile makes that scaffolding clear and traceable. For more information on Make files check out Mike Bostock's post here (link) and for the inspiration for HRDAG's project oriented workflow check out Jenny Bryan's post here (link). 

For this project I have a clean task, a test task, and a write task each with its own Makefile, input, output, and src folder for the source code. 

## Clean and Summarize {-}

I start with the clean task. In the input folder of this task I include the two datasets of with reported deaths, the src folder contains the R code to clean up the code. I used RStudio to test the code for bugs (with frequent restarts and fresh environments) and use Microsoft Visual Studio Code to update the code that gets pushed to the project Github repository. I had a small bug early on with an error message I didn't want to immediately address so I created an issue on the GitHub to pick it back up later. I knew where the code had issues but I could count on the rest of it working as expected if (when) I'd need to spend time on other projects. This also had the added benefit (trap?) of making me feel like I'd actually made progress instead of staring down the endless empty field of .R file with however many tasks left to code. Win!

The first dataset includes initial deaths reported from 12 June 2019 -- 10 September 2019. The second file contains additional deaths reported from 1 January 2019 -- 14 December 2019. Our client would like us to determine if the number of deaths reported during a specific time period appeared to be unusually high, and the relationship of these reported detahs to dates of external events. 

First, we'd like to do some exploratory data analysis and summarize how much complete information we have for each individual reported on in the dataset.

To do this, we pull in the clean data from the clean task's output folder. #FIXME: add in more detail about steps in clean task

```{r, cleanand sum, message=FALSE}
require (pacman)
pacman::p_load(dplyr,styler,tidyverse,readr,assertr, ggplot2,scales,incidence,exactci)

files <- list(input1=here::here("clean/output/death1_clean.txt"),
               input2=here::here("clean/output/death2_clean.txt"))
stopifnot(is.list(files)== TRUE)

death1 <- readr::read_delim(files$input1, delim="|")

death2 <- readr::read_delim(files$input2, delim="|")

```

In order to determine if the number of deaths reported is abnormally high, we use an epidemiological (or epi) curve to see if this number of deaths per day appears to spike anywhere. Epi curves are often used in the investigation into whether an outbreak of an outcome has occured and can even suggest a means of propogation; curves for infections transmitted from person to person have different shapes than curves of diseases transmitted from a water source, for example. 

In our data, if an epidemic of deaths were occuring, we would expect to see a spike in the number of deaths reported per day. The day on which most deaths were reported in the first set was `r getmode(death1$DOD)` and in the second set was `r getmode(death2$DOD)`. It is unclear whether or not these would be high enough to be considered spikes.

It looks like we have some people recorded who are not deaths, since we are only interested in the number of deaths over time, we remove all rows where the person's status is "Not_death". For the first set we'll be removing `r table(death1$status)[["Not_death"]]` people and in the second set we'll be removing `r table(death2$status)[["Not_death"]]` people. ##FIXME: discuss in past tense

In the first set there are `r table(death1$sex)[["F"]]` Females and `r table(death1$sex)[["M"]]` Males with overall mean age of `r round(mean(death1$age, na.rm=T), 0)` and a median age of `r quantile(death1$age, probs=c(0.5), na.rm=TRUE)[[1]]`. In the second set there are `r table(death2$sex)[["F"]]` Females and `r table(death2$sex)[["M"]]` Males with overall mean age of `r round(mean(death2$age, na.rm=T), 0)` and a median age of `r quantile(death2$age, probs=c(0.5), na.rm=TRUE)[[1]]`. 

Fortunately there appears to be very little missing data in the dates, this will be critical in setting up our epi curves.

## Daily Epi Curve (All Reported Deaths) From 1st Dataset {-}

The first set includes initial deaths reported from 12 June 2019 -- 10 September 2019, 91 days or approximately 3 months. The second set contains additional deaths reported from 1 January 2019 -- 14 December 2019, 348 days or approximately 11 months.

In order to examine the frequency of reported deaths per day across the time period provided, I use the incidence package to obtain the number of deaths reported each day and plot this against all of the days for which we have data.

```{r epic_DOD1, message=FALSE, echo=FALSE}
# compute daily incidence
date_case1<- incidence(death1$date, interval = 1 )

# plot 
epiplot1<-
  plot(date_case1, border = "black", show_cases =TRUE, 
       ylab = "Reported Deaths", xlab= "Date") +
  scale_x_date(labels = date_format("%d %b %Y")) +
  theme_grey() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, color = "black")) +
  coord_fixed(ratio=3)
epiplot1

```
This pattern appears to suggest that deaths spiked in the beginning of June and end of August into September. However, since these are only from approximately 100 people over 3 months, it is not clear that the days on which we see high numbers of deaths would be outside of what we would expect to see within normal variation in this population. 

Let's examine the 2nd set of data with around 900 people, first removing those people who are not actually dead, leaving us with nrows(death2) deaths over a period of approximately 11 months. 

## Daily Epi Curve (All Reported Deaths) From 2nd Dataset {-}

```{r epic_DOD2, message=FALSE, echo=FALSE}
# compute daily incidence
date_case2<- incidence(death2$date, interval = 1 )

# plot
epiplot2<-
  plot(date_case2, border = "black", show_cases=TRUE, 
       ylab = "Reported Deaths", xlab= "Date") +
  scale_x_date(labels = date_format("%d %b %Y")) +
  theme_grey() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, color = "black")) +
  coord_fixed(ratio=5)

epiplot2
```
This graph suggests that spikes occured in June or July but is 6 deaths reported per day significantly greater than 4 or 5 deaths reported in a day? With more data it appears even less clear if the days which have "high" numbers of deaths are outside of the normal amount of vartiation around the mean that we would expect.

As is common with data in the human rights context, it can often be difficult to obtain official statistics on incidence of a particular outcome of interest. Some group may have an interest in that data not existing in one central location or it may simply never have been collected. Either way, this requires us to try a classical statistical approach.

These deaths are counts collected in a specific time period.This means that they can be assessed in the context of whether or not the represent a normally distributed discrete random variable in a Poisson distribution. Data which follow a normal Posisson distribution exhibit expected amounts of variation around the mean number of events in a given time period. 

In order to establish whether or not these data suggest spikes in numbers around events of interest to the client we construct our hypothesis to ask: given the mean number of deaths reported per day prior to the date of interest, is the mean number of deaths per day significantly different after this date? Specifically, on the days when we are seeing what appear to be a high number of deaths per day, are these numbers statistically significantly greater than we would expect with normal variation? 

## Hypothesis testing {-}

Next, we call in data from the test task. In this task we prepared our data for hypothesis testing by calculating the mean frequency of deaths per day before and after each of our two dates of interest.

We will compare them using a Poisson test in the stat's package's ppois function to test the likliehood that the mean frequency of deaths we are observing prior to the date of interest is statistically significantly different from the mean frequency of deaths per day following the date of interest. Since we want to know specifically if the frequency of deaths we are observing after the date of interest is is greater than the mean frequency prior to the date of interest, we perform a one-tailed test. 

For example, if the mean number of deaths reported per day prior to the date of interest is 4 and we're seeing a mean of 7 deaths reported per day, are these two means statistically significantly different from one another?

``` {r hypothesistest, message = FALSE}

files <- list(input1=here::here("test/output/death1_test.txt"),
              input2=here::here("test/output/death2_test.txt"))
              
death1 <- readr::read_delim(files$input1, delim="|")
death2 <- readr::read_delim(files$input2, delim="|")

#test 1
100*ppois(maxdeath1, mucpd1, lower.tail=FALSE)
poisson.test(round(mucpd1), 1, round(maxdeath1), alternative = "g")

#test 2
100*ppois(maxdeath2, mucpd2, lower.tail=FALSE)
poisson.test(round(mucpd2), 1, round(maxdeath2), alternative = "g")

```
Given the mean number of deaths reported per day in set one, `r mucpd1`, and the highest number of deaths we see in set 1, `r maxdeath1`   



## Conclusion {-}


```{r session_info, message=FALSE, include=FALSE}
sessionInfo()
```
<!---- done ---->
